{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_qsvm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3GueDegG7t4nRmsKL2fhu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifsmtp1/quantum-svm/blob/main/iris_qvc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv6fmbOMPs03"
      },
      "source": [
        "!pip install --upgrade qiskit==0.19.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit-machine-learning"
      ],
      "metadata": {
        "id": "nzsfkeGF_LlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import BasicAer\n",
        "from qiskit.utils import QuantumInstance, algorithm_globals\n",
        "from qiskit.algorithms.optimizers import COBYLA\n",
        "from qiskit.circuit.library import TwoLocal, ZZFeatureMap\n",
        "from qiskit_machine_learning.algorithms import VQC\n",
        "from qiskit_machine_learning.datasets import ad_hoc_data\n"
      ],
      "metadata": {
        "id": "o3BGSGY4Gx7l"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from qiskit.exceptions import MissingOptionalLibraryError\n",
        "from qiskit_machine_learning.datasets.dataset_helper import (\n",
        "    features_and_labels_transform,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "bJL3WOHQ5NZ0"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iris(training_size, test_size, n, plot_data=False, one_hot=True):\n",
        "    \"\"\"returns iris dataset\"\"\"\n",
        "    class_labels = [r\"A\", r\"B\", r\"C\"]\n",
        "    data, target = datasets.load_iris(return_X_y=True)\n",
        "    sample_train, sample_test, label_train, label_test = train_test_split(\n",
        "        data, target, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    # Now we standardize for gaussian around 0 with unit variance\n",
        "    std_scale = StandardScaler().fit(sample_train)\n",
        "    sample_train = std_scale.transform(sample_train)\n",
        "    sample_test = std_scale.transform(sample_test)\n",
        "\n",
        "    # Now reduce number of features to number of qubits\n",
        "    pca = PCA(n_components=n).fit(sample_train)\n",
        "    sample_train = pca.transform(sample_train)\n",
        "    sample_test = pca.transform(sample_test)\n",
        "\n",
        "    # Scale to the range (-1,+1)\n",
        "    samples = np.append(sample_train, sample_test, axis=0)\n",
        "    minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
        "    sample_train = minmax_scale.transform(sample_train)\n",
        "    sample_test = minmax_scale.transform(sample_test)\n",
        "\n",
        "    # Pick training size number of samples from each distro\n",
        "    training_input = {\n",
        "        key: (sample_train[label_train == k, :])[:training_size]\n",
        "        for k, key in enumerate(class_labels)\n",
        "    }\n",
        "    test_input = {\n",
        "        key: (sample_test[label_test == k, :])[:test_size] for k, key in enumerate(class_labels)\n",
        "    }\n",
        "\n",
        "    training_feature_array, training_label_array = features_and_labels_transform(\n",
        "        training_input, class_labels, one_hot\n",
        "    )\n",
        "    test_feature_array, test_label_array = features_and_labels_transform(\n",
        "        test_input, class_labels, one_hot\n",
        "    )\n",
        "\n",
        "    if plot_data:\n",
        "        try:\n",
        "            import matplotlib.pyplot as plt\n",
        "        except ImportError as ex:\n",
        "            raise MissingOptionalLibraryError(\n",
        "                libname=\"Matplotlib\", name=\"iris\", pip_install=\"pip install matplotlib\"\n",
        "            ) from ex\n",
        "        for k in range(0, 3):\n",
        "            plt.scatter(\n",
        "                sample_train[label_train == k, 0][:training_size],\n",
        "                sample_train[label_train == k, 1][:training_size],\n",
        "            )\n",
        "\n",
        "        plt.title(\"Iris dataset\")\n",
        "        plt.show()\n",
        "\n",
        "    return (\n",
        "        training_feature_array,\n",
        "        training_label_array,\n",
        "        test_feature_array,\n",
        "        test_label_array,\n",
        "    )"
      ],
      "metadata": {
        "id": "YRuF98dW5m8G"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = 2  # dimension of each data point\n",
        "training_size = 100\n",
        "test_size = 10\n",
        "one_hot=True"
      ],
      "metadata": {
        "id": "MzNUZLxfy2Fh"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [r\"A\", r\"B\", r\"C\"]\n",
        "data, target = datasets.load_iris(return_X_y=True)\n",
        "sample_train, sample_test, label_train, label_test = train_test_split(\n",
        "        data, target, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    # Now we standardize for gaussian around 0 with unit variance\n",
        "std_scale = StandardScaler().fit(sample_train)\n",
        "sample_train = std_scale.transform(sample_train)\n",
        "sample_test = std_scale.transform(sample_test)\n",
        "\n",
        "# Now reduce number of features to number of qubits\n",
        "pca = PCA(n_components=feature_dim).fit(sample_train)\n",
        "sample_train = pca.transform(sample_train)\n",
        "sample_test = pca.transform(sample_test)\n",
        "\n",
        "    # Scale to the range (-1,+1)\n",
        "samples = np.append(sample_train, sample_test, axis=0)\n",
        "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
        "sample_train = minmax_scale.transform(sample_train)\n",
        "sample_test = minmax_scale.transform(sample_test)\n",
        "\n",
        "    # Pick training size number of samples from each distro\n",
        "training_input = {\n",
        "        key: (sample_train[label_train == k, :])[:training_size]\n",
        "        for k, key in enumerate(class_labels)\n",
        "    }\n",
        "test_input = {\n",
        "        key: (sample_test[label_test == k, :])[:test_size] for k, key in enumerate(class_labels)\n",
        "    }\n",
        "\n",
        "training_feature_array, training_label_array = features_and_labels_transform(\n",
        "        training_input, class_labels, one_hot\n",
        "    )\n",
        "test_feature_array, test_label_array = features_and_labels_transform(\n",
        "        test_input, class_labels, one_hot\n",
        "    )"
      ],
      "metadata": {
        "id": "nvKeR8XQ6Hkn"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the SVM model\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "#Fit the model for the data\n",
        "classifier.fit(sample_train, label_train)"
      ],
      "metadata": {
        "id": "dPYIpCDdGQST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a430de-2607-4d4d-d39f-2b4007a98fa8"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(sample_test)"
      ],
      "metadata": {
        "id": "y8QLvKuE7D1y"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = sample_train, y = label_train, cv = 10)"
      ],
      "metadata": {
        "id": "SHuNrFs-7J1r"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=2, entanglement=\"linear\")\n",
        "ansatz = TwoLocal(feature_map.num_qubits, ['ry', 'rz'], 'cz', reps=3)\n",
        "vqc = VQC(feature_map=feature_map,\n",
        "          ansatz=ansatz,\n",
        "          optimizer=COBYLA(maxiter=100),\n",
        "          quantum_instance=QuantumInstance(BasicAer.get_backend('statevector_simulator'),\n",
        "                                           shots=1024,\n",
        "                                           seed_simulator=seed,\n",
        "                                           seed_transpiler=seed)\n",
        "          )\n",
        "vqc.fit(training_features, training_labels)\n",
        "\n",
        "score = vqc.score(test_features, test_labels)\n",
        "print(f\"Testing accuracy: {score:0.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfrYWzFqGtWz",
        "outputId": "f682315a-e706-4b60-e3ce-69eb7c72a218"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Accuracy QISKIT VQC: {:.2f} %\".format(score.mean()*100))\n",
        "print(\"Testing Accuracy sklearn SVC: {:.2f} %\".format(accuracies.mean()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tYgh0CY8DE3",
        "outputId": "101d539f-363d-4195-bbc4-5fd9345bcc94"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy QISKIT VQC: 50.00 %\n",
            "Testing Accuracy sklearn SVC: 90.71 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "YpFTpR2IQmGn",
        "outputId": "d73b413b-1eca-44f1-ef06-5faaa36557d8"
      },
      "source": [
        "import qiskit.tools.jupyter\n",
        "%qiskit_version_table\n",
        "%qiskit_copyright"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Version Information</h3><table><tr><th>Qiskit Software</th><th>Version</th></tr><tr><td><code>qiskit-terra</code></td><td>0.19.2</td></tr><tr><td><code>qiskit-ignis</code></td><td>0.3.0</td></tr><tr><td><code>qiskit-aqua</code></td><td>0.7.0</td></tr><tr><td><code>qiskit</code></td><td>0.19.1</td></tr><tr><td><code>qiskit-machine-learning</code></td><td>0.3.1</td></tr><tr><th>System information</th></tr><tr><td>Python version</td><td>3.7.12</td></tr><tr><td>Python compiler</td><td>GCC 7.5.0</td></tr><tr><td>Python build</td><td>default, Jan 15 2022 18:48:18</td></tr><tr><td>OS</td><td>Linux</td></tr><tr><td>CPUs</td><td>1</td></tr><tr><td>Memory (Gb)</td><td>12.686653137207031</td></tr><tr><td colspan='2'>Sat Feb 19 07:08:05 2022 UTC</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style='width: 100%; background-color:#d5d9e0;padding-left: 10px; padding-bottom: 10px; padding-right: 10px; padding-top: 5px'><h3>This code is a part of Qiskit</h3><p>&copy; Copyright IBM 2017, 2022.</p><p>This code is licensed under the Apache License, Version 2.0. You may<br>obtain a copy of this license in the LICENSE.txt file in the root directory<br> of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.<p>Any modifications or derivative works of this code must retain this<br>copyright notice, and modified files need to carry a notice indicating<br>that they have been altered from the originals.</p></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}